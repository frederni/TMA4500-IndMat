{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building a recommender system with embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "                <script type=\"application/javascript\" id=\"jupyter_black\">\n",
       "                (function() {\n",
       "                    if (window.IPython === undefined) {\n",
       "                        return\n",
       "                    }\n",
       "                    var msg = \"WARNING: it looks like you might have loaded \" +\n",
       "                        \"jupyter_black in a non-lab notebook with \" +\n",
       "                        \"`is_lab=True`. Please double check, and if \" +\n",
       "                        \"loading with `%load_ext` please review the README!\"\n",
       "                    console.log(msg)\n",
       "                    alert(msg)\n",
       "                })()\n",
       "                </script>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%reload_ext jupyter_black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning up the datasets\n",
    "from typing import Iterable\n",
    "\n",
    "\n",
    "def load_min_data(filename: str | Iterable):\n",
    "    dfs = []\n",
    "    if isinstance(filename, str):\n",
    "        filename = [filename]\n",
    "    for fn in filename:\n",
    "        df = pd.read_csv(fn)\n",
    "        # All min-datasets have an index column which has to be dropped:\n",
    "        dfs.append(df.drop(df.columns[0], axis=1))\n",
    "    return dfs\n",
    "\n",
    "\n",
    "def clean_customer_data(df):\n",
    "    # df = df.drop(\"FN\", axis=1) # I they're not exactly equal\n",
    "    df.loc[\n",
    "        ~df[\"fashion_news_frequency\"].isin([\"Regularly\", \"Monthly\"]),\n",
    "        \"fashion_news_frequency\",\n",
    "    ] = \"None\"\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New data loading principle\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from typing import Tuple\n",
    "\n",
    "\n",
    "class Data_HM(Dataset):\n",
    "    \"\"\"This is the general HM Dataset class whose children are train-dataset and validation-dataset\n",
    "\n",
    "    Args:\n",
    "        Dataset: Abstract Dataset class from pyTorch\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        total_cases: int,\n",
    "        portion_negatives: float,\n",
    "        df_transactions: pd.DataFrame,\n",
    "        df_articles: pd.DataFrame,\n",
    "        df_customers: pd.DataFrame,\n",
    "        train_portion: float | None = None,\n",
    "        test_portion: float | None = None,\n",
    "    ) -> None:\n",
    "        super().__init__()  # TODO not sure if we need this\n",
    "        self.pos, self.neg = self.generate_dataset(\n",
    "            total_cases, portion_negatives, df_transactions\n",
    "        )\n",
    "        self.df = pd.concat(\n",
    "            [\n",
    "                self.merge_dfs_add_label(\n",
    "                    self.pos,\n",
    "                    df_articles,\n",
    "                    df_customers,\n",
    "                    positive=True,\n",
    "                ),\n",
    "                self.merge_dfs_add_label(\n",
    "                    self.neg,\n",
    "                    df_articles,\n",
    "                    df_customers,\n",
    "                    positive=False,\n",
    "                ),\n",
    "            ]\n",
    "        ).reset_index(drop=True)\n",
    "        self.train, self.test = self.split(train_portion, test_portion)\n",
    "\n",
    "    def generate_dataset(\n",
    "        self, total_cases: int, portion_negatives: float, df_transactions: pd.DataFrame\n",
    "    ) -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
    "        \"\"\"Produce DataFrames for positive labels and generated negative samples\n",
    "\n",
    "        Args:\n",
    "            total_cases (int): Total number of transactions\n",
    "            portion_negatives (float): The portion of the `total_cases` that should be negative. Balanced 0/1 when 0.5\n",
    "            df_transactions (pd.DataFrame): Transactions to pull samples/generate samples from\n",
    "\n",
    "        Returns:\n",
    "            Tuple[pd.DataFrame, pd.DataFrame]: _description_\n",
    "        \"\"\"\n",
    "        assert (\n",
    "            0 <= portion_negatives <= 1\n",
    "        ), r\"portion negatives must be a float between 0%=0.0 and 100%=1.0!\"\n",
    "        n_positive = int(total_cases * (1 - portion_negatives))\n",
    "        n_negative = int(total_cases * portion_negatives)\n",
    "        df_positive = df_transactions.sample(n=n_positive).reset_index(drop=True)\n",
    "        df_positive = df_positive[[\"customer_id\", \"article_id\"]]\n",
    "\n",
    "        # Sampling negative labels:\n",
    "        #   We select a random combination of `customer_id`, `article_id`, and ensure that this is not a true transaction.\n",
    "        #   Then we write this tuple to a csv which is transformed into a DataFrame similar to `df_positive`\n",
    "\n",
    "        num_written = 0\n",
    "        tmpStr = \"customer_id,article_id\\n\"\n",
    "        while num_written < n_negative:\n",
    "            # Choose random customer and article\n",
    "            selection = np.array(  # TODO this can probably be optimized further\n",
    "                [\n",
    "                    df_transactions[\"customer_id\"].sample().values,\n",
    "                    df_transactions[\"article_id\"].sample().values,\n",
    "                ]\n",
    "            ).flatten()\n",
    "            if not (\n",
    "                (df_transactions[\"customer_id\"] == selection[0])\n",
    "                & (df_transactions[\"article_id\"] == selection[1])\n",
    "            ).any():\n",
    "                tmpStr += f\"{selection[0]}, {selection[1]}\\n\"\n",
    "                num_written += 1\n",
    "        with open(\"tmp.csv\", \"w\") as f:\n",
    "            f.write(tmpStr)\n",
    "        df_negative = pd.read_csv(\"tmp.csv\")\n",
    "        os.remove(\"tmp.csv\")\n",
    "        return df_positive, df_negative\n",
    "\n",
    "    def merge_dfs_add_label(\n",
    "        self,\n",
    "        df_transactions: pd.DataFrame,\n",
    "        df_articles: pd.DataFrame,\n",
    "        df_customers: pd.DataFrame,\n",
    "        positive: bool = False,\n",
    "    ) -> pd.DataFrame:\n",
    "        \"\"\"Merge customer and article data to the sampled data `df_transactions`, excluding customer/article IDs\n",
    "\n",
    "        Args:\n",
    "            df_transactions (pd.DataFrame): DataFrame from `generate_dataset`\n",
    "            df_articles (pd.DataFrame): Articles DataFrame\n",
    "            df_customers (pd.DataFrame): Customers DataFrame\n",
    "            positive (bool, optional): Wether or not df_transactions represent positive labels. Defaults to False.\n",
    "\n",
    "        Returns:\n",
    "            pd.DataFrame: DF with all columns included\n",
    "        \"\"\"\n",
    "        columns_articles = [\n",
    "            \"article_id\",\n",
    "            \"prod_name\",\n",
    "            \"product_type_name\",\n",
    "            \"product_group_name\",\n",
    "            \"graphical_appearance_name\",\n",
    "            \"colour_group_name\",\n",
    "            \"perceived_colour_value_name\",\n",
    "            \"perceived_colour_master_name\",\n",
    "            \"department_name\",\n",
    "            \"index_name\",\n",
    "            \"index_group_name\",\n",
    "            \"section_name\",\n",
    "            \"garment_group_name\",\n",
    "            \"detail_desc\",\n",
    "        ]\n",
    "        # TODO consider storing blacklisted cols instead of whitelisted\n",
    "\n",
    "        df_articles = df_articles[columns_articles]\n",
    "\n",
    "        df = pd.merge(\n",
    "            df_transactions, df_customers, how=\"inner\", on=[\"customer_id\"]\n",
    "        ).drop([\"customer_id\"], axis=1)\n",
    "        df = pd.merge(df, df_articles, how=\"inner\", on=[\"article_id\"]).drop(\n",
    "            [\"article_id\"], axis=1\n",
    "        )\n",
    "        df[\"label\"] = 1 if positive else 0\n",
    "        return df\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df.index)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row, label = self.df.iloc[idx, :-1], self.df.iloc[idx, -1]\n",
    "        if self.transform:\n",
    "            row = self.transform(row)\n",
    "        if self.target_transform:\n",
    "            label = self.target_transform(label)\n",
    "        return row, label\n",
    "\n",
    "    def split(\n",
    "        self, train_portion: float | None = None, test_portion: float | None = None\n",
    "    ) -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
    "        \"\"\"Split full dataset into training and validation set. Note that only one of train_portion or\n",
    "            test_portion are required (test_portion = 100% - test_portion)\n",
    "\n",
    "        Args:\n",
    "            train_portion (float | None, optional): Percentage of rows assigned to training set. Defaults to None.\n",
    "            test_portion (float | None, optional): Percentage of rows assigned to validation set. Defaults to None.\n",
    "\n",
    "        Returns:\n",
    "            Tuple[pd.DataFrame, pd.DataFrame]: Train-set and validation-set\n",
    "        \"\"\"\n",
    "        assert any(\n",
    "            [train_portion, test_portion]\n",
    "        ), \"At least one of train or test portion must be float\"\n",
    "        if train_portion is None:\n",
    "            train_portion = 1 - test_portion\n",
    "        train = self.df.sample(frac=train_portion)\n",
    "        test = (\n",
    "            pd.merge(self.df, train, indicator=True, how=\"outer\")\n",
    "            .query('_merge==\"left_only\"')\n",
    "            .drop(\"_merge\", axis=1)\n",
    "        )\n",
    "        return train.reset_index(drop=True), test.reset_index(drop=True)\n",
    "\n",
    "\n",
    "class HM_train(Data_HM):\n",
    "    def __init__(\n",
    "        self,\n",
    "        total_cases,\n",
    "        portion_negatives,\n",
    "        df_transactions,\n",
    "        df_articles,\n",
    "        df_customers: pd.DataFrame,\n",
    "        train_portion=None,\n",
    "        test_portion=None,\n",
    "    ) -> None:\n",
    "        super().__init__(\n",
    "            total_cases,\n",
    "            portion_negatives,\n",
    "            df_transactions,\n",
    "            df_articles,\n",
    "            df_customers,\n",
    "            train_portion,\n",
    "            test_portion,\n",
    "        )\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row, label = self.train.iloc[idx, :-1], self.train.iloc[idx, -1]\n",
    "        if self.transform:\n",
    "            row = self.transform(row)\n",
    "        if self.target_transform:\n",
    "            label = self.target_transform(label)\n",
    "        return row, label\n",
    "\n",
    "\n",
    "class HM_val(Data_HM):\n",
    "    def __init__(\n",
    "        self,\n",
    "        total_cases,\n",
    "        portion_negatives,\n",
    "        df_transactions,\n",
    "        df_articles,\n",
    "        df_customers: pd.DataFrame,\n",
    "        train_portion=None,\n",
    "        test_portion=None,\n",
    "    ) -> None:\n",
    "        super().__init__(\n",
    "            total_cases,\n",
    "            portion_negatives,\n",
    "            df_transactions,\n",
    "            df_articles,\n",
    "            df_customers,\n",
    "            train_portion,\n",
    "            test_portion,\n",
    "        )\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row, label = self.test.iloc[idx, :-1], self.test.iloc[idx, -1]\n",
    "        if self.transform:\n",
    "            row = self.transform(row)\n",
    "        if self.target_transform:\n",
    "            label = self.target_transform(label)\n",
    "        return row, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embedding models (same model as Mind Data example)\n",
    "\n",
    "\n",
    "class HM_model(torch.nn.Module):\n",
    "    def __init__(self, num_customer, num_transactions, embedding_size):\n",
    "        super(HM_model, self).__init__()\n",
    "        self.customer_embed = torch.nn.Embedding(\n",
    "            num_embeddings=num_customer, embedding_dim=embedding_size\n",
    "        )\n",
    "        self.trans_embed = torch.nn.Embedding(\n",
    "            num_embeddings=num_transactions, embedding_dim=embedding_size\n",
    "        )\n",
    "\n",
    "    def forward(self, users, items):\n",
    "        customer_embed = self.customer_embed(users)\n",
    "        trans_embed = self.trans_embed(items)\n",
    "        dot_prod = torch.sum(torch.mul(customer_embed, trans_embed), 1)\n",
    "        return torch.sigmoid(dot_prod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Psudeo one epoch\n",
    "epoch_loss = 0\n",
    "* For each point in data\n",
    "    * retrieve column info + label and set to separate variables\n",
    "    * optimizer.zero_grad # Not sure if we should do this or not..\n",
    "    * compute prediction via model(row_info)\n",
    "    * compute loss_value via loss(prediction.view(-1), labels)\n",
    "    * loss.backward()\n",
    "    * optimizer.step()\n",
    "    * Potentially: LR scheduler.step()\n",
    "\n",
    "    epoch_loss += loss_value\n",
    "\n",
    "print(\"Epoch\", \"Loss\", \"Loss per data sample\", sep=\"\\t\")\n",
    "print(epoch+1, epoch_loss, epoch_loss/len(data), sep=\"\\t\")\n",
    "print(\"-\"*20)\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def train_one_epoch(model: HM_model, data, epoch_num: int, optimizer, loss):\n",
    "    epoch_loss = 0\n",
    "    for batch, row in enumerate(data):\n",
    "        optimizer.zero_grad()\n",
    "        pred = model(row)\n",
    "        loss_value = loss(pred.view(-1), labels)\n",
    "        loss_value.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss_value\n",
    "\n",
    "\n",
    "def train(model, train_DL, params):\n",
    "    # Uses binary cross entropy at the moment\n",
    "    loss_metric = torch.nn.BCELoss()  # TODO change to MAP12 once the rest works\n",
    "\n",
    "    \"\"\" Psudeocode\n",
    "    * Initialize loss function and optimizer\n",
    "    * For epoch in epochs:\n",
    "        * Retrieve data from train_DL # Example uses custom sample_training_data \n",
    "        * train_one_epoch(...)\n",
    "        * Report eval statistics for each n-th epoch\n",
    "            * Both training accuracy and validation accuracy\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "def validate(model, DL, train=False):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FN</th>\n",
       "      <th>Active</th>\n",
       "      <th>club_member_status</th>\n",
       "      <th>fashion_news_frequency</th>\n",
       "      <th>age</th>\n",
       "      <th>postal_code</th>\n",
       "      <th>prod_name</th>\n",
       "      <th>product_type_name</th>\n",
       "      <th>product_group_name</th>\n",
       "      <th>graphical_appearance_name</th>\n",
       "      <th>colour_group_name</th>\n",
       "      <th>perceived_colour_value_name</th>\n",
       "      <th>perceived_colour_master_name</th>\n",
       "      <th>department_name</th>\n",
       "      <th>index_name</th>\n",
       "      <th>index_group_name</th>\n",
       "      <th>section_name</th>\n",
       "      <th>garment_group_name</th>\n",
       "      <th>detail_desc</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ACTIVE</td>\n",
       "      <td>None</td>\n",
       "      <td>31.0</td>\n",
       "      <td>71b88711bd37db08ac1549d73432852f664cb48be8d893...</td>\n",
       "      <td>Emily</td>\n",
       "      <td>Blouse</td>\n",
       "      <td>Garment Upper body</td>\n",
       "      <td>Solid</td>\n",
       "      <td>Dark Green</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Green</td>\n",
       "      <td>Blouse</td>\n",
       "      <td>Ladieswear</td>\n",
       "      <td>Ladieswear</td>\n",
       "      <td>Womens Everyday Collection</td>\n",
       "      <td>Blouses</td>\n",
       "      <td>Short top in an airy cotton weave. Square neck...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ACTIVE</td>\n",
       "      <td>None</td>\n",
       "      <td>48.0</td>\n",
       "      <td>4385d55783e67067b9768f0877107d3e6cd64f3bee08ce...</td>\n",
       "      <td>Rebecka Dress</td>\n",
       "      <td>Dress</td>\n",
       "      <td>Garment Full body</td>\n",
       "      <td>All over pattern</td>\n",
       "      <td>White</td>\n",
       "      <td>Light</td>\n",
       "      <td>White</td>\n",
       "      <td>Jersey</td>\n",
       "      <td>Ladieswear</td>\n",
       "      <td>Ladieswear</td>\n",
       "      <td>Mama</td>\n",
       "      <td>Jersey Fancy</td>\n",
       "      <td>Short, fitted dress in soft, organic cotton je...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ACTIVE</td>\n",
       "      <td>None</td>\n",
       "      <td>33.0</td>\n",
       "      <td>bf98f222ef9eb34b3bba2745452d5f6d2f395edc79a4f1...</td>\n",
       "      <td>Twister</td>\n",
       "      <td>Dress</td>\n",
       "      <td>Garment Full body</td>\n",
       "      <td>Melange</td>\n",
       "      <td>Grey</td>\n",
       "      <td>Medium Dusty</td>\n",
       "      <td>Grey</td>\n",
       "      <td>Jersey Basic</td>\n",
       "      <td>Ladieswear</td>\n",
       "      <td>Ladieswear</td>\n",
       "      <td>Womens Everyday Basics</td>\n",
       "      <td>Jersey Basic</td>\n",
       "      <td>Calf-length jersey dress with draped sides, sh...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>ACTIVE</td>\n",
       "      <td>Regularly</td>\n",
       "      <td>31.0</td>\n",
       "      <td>5d3e0bac03cdc876b5a1d84fd7c2b2e7cefa40ddbe62be...</td>\n",
       "      <td>Simple as That Triangle Top</td>\n",
       "      <td>Bikini top</td>\n",
       "      <td>Swimwear</td>\n",
       "      <td>Other structure</td>\n",
       "      <td>Dark Green</td>\n",
       "      <td>Medium Dusty</td>\n",
       "      <td>Green</td>\n",
       "      <td>Swimwear</td>\n",
       "      <td>Lingeries/Tights</td>\n",
       "      <td>Ladieswear</td>\n",
       "      <td>Womens Swimwear, beachwear</td>\n",
       "      <td>Swimwear</td>\n",
       "      <td>Lined, non-wired, triangle bikini top with a w...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>ACTIVE</td>\n",
       "      <td>Regularly</td>\n",
       "      <td>29.0</td>\n",
       "      <td>efd9030a7d5b5f1a6d03a1a24b1fab9931492256ce29e5...</td>\n",
       "      <td>Charlene cardigan</td>\n",
       "      <td>Cardigan</td>\n",
       "      <td>Garment Upper body</td>\n",
       "      <td>Melange</td>\n",
       "      <td>Grey</td>\n",
       "      <td>Medium Dusty</td>\n",
       "      <td>Grey</td>\n",
       "      <td>Knitwear</td>\n",
       "      <td>Ladieswear</td>\n",
       "      <td>Ladieswear</td>\n",
       "      <td>Womens Trend</td>\n",
       "      <td>Knitwear</td>\n",
       "      <td>Cardigan in chunky-knit, soft wool with button...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>ACTIVE</td>\n",
       "      <td>Regularly</td>\n",
       "      <td>27.0</td>\n",
       "      <td>76c7d8747a83d1c09d66e311b142d77c0fa1d8fb646c5a...</td>\n",
       "      <td>POW Meet the parents dress.</td>\n",
       "      <td>Dress</td>\n",
       "      <td>Garment Full body</td>\n",
       "      <td>Solid</td>\n",
       "      <td>Dark Pink</td>\n",
       "      <td>Medium Dusty</td>\n",
       "      <td>Pink</td>\n",
       "      <td>Jersey</td>\n",
       "      <td>Ladieswear</td>\n",
       "      <td>Ladieswear</td>\n",
       "      <td>H&amp;M+</td>\n",
       "      <td>Jersey Fancy</td>\n",
       "      <td>Calf-length lace dress with adjustable spaghet...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>ACTIVE</td>\n",
       "      <td>Regularly</td>\n",
       "      <td>50.0</td>\n",
       "      <td>4e63dc705eb70e92b59132da6ff80f9841982d030f5178...</td>\n",
       "      <td>Cava Shirt Dress new</td>\n",
       "      <td>Dress</td>\n",
       "      <td>Garment Full body</td>\n",
       "      <td>All over pattern</td>\n",
       "      <td>Black</td>\n",
       "      <td>Dark</td>\n",
       "      <td>Black</td>\n",
       "      <td>Dresses</td>\n",
       "      <td>Divided</td>\n",
       "      <td>Divided</td>\n",
       "      <td>Divided Collection</td>\n",
       "      <td>Dresses Ladies</td>\n",
       "      <td>Short dress in a softly draping weave with a c...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>ACTIVE</td>\n",
       "      <td>Regularly</td>\n",
       "      <td>21.0</td>\n",
       "      <td>00b7efd47eeb50702752f1b9ffd8ebd953a54124aead10...</td>\n",
       "      <td>Timeless Push Bra</td>\n",
       "      <td>Bikini top</td>\n",
       "      <td>Swimwear</td>\n",
       "      <td>Other structure</td>\n",
       "      <td>Black</td>\n",
       "      <td>Dark</td>\n",
       "      <td>Black</td>\n",
       "      <td>Swimwear</td>\n",
       "      <td>Lingeries/Tights</td>\n",
       "      <td>Ladieswear</td>\n",
       "      <td>Womens Swimwear, beachwear</td>\n",
       "      <td>Swimwear</td>\n",
       "      <td>Fully lined bikini top with a textured-stripe ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ACTIVE</td>\n",
       "      <td>None</td>\n",
       "      <td>44.0</td>\n",
       "      <td>91bbfabb4917109c8a4d300fa95e514b7bbc251cea44e3...</td>\n",
       "      <td>Chia Seamless HW Tights</td>\n",
       "      <td>Leggings/Tights</td>\n",
       "      <td>Garment Lower body</td>\n",
       "      <td>Solid</td>\n",
       "      <td>Orange</td>\n",
       "      <td>Bright</td>\n",
       "      <td>Orange</td>\n",
       "      <td>Ladies Sport Bottoms</td>\n",
       "      <td>Sport</td>\n",
       "      <td>Sport</td>\n",
       "      <td>Ladies H&amp;M Sport</td>\n",
       "      <td>Jersey Fancy</td>\n",
       "      <td>Sports tights in ribbed, fast-drying functiona...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PRE-CREATE</td>\n",
       "      <td>None</td>\n",
       "      <td>25.0</td>\n",
       "      <td>570e2e8d4b0f09c94a88e52fb936234bf57da9943e142a...</td>\n",
       "      <td>Headphones EARS</td>\n",
       "      <td>Other accessories</td>\n",
       "      <td>Accessories</td>\n",
       "      <td>Solid</td>\n",
       "      <td>Light Turquoise</td>\n",
       "      <td>Light</td>\n",
       "      <td>Turquoise</td>\n",
       "      <td>Girls Small Acc/Bags</td>\n",
       "      <td>Children Accessories, Swimwear</td>\n",
       "      <td>Baby/Children</td>\n",
       "      <td>Kids Accessories, Swimwear &amp; D</td>\n",
       "      <td>Accessories</td>\n",
       "      <td>Adjustable, glittery, on-ear headphones with p...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>ACTIVE</td>\n",
       "      <td>Regularly</td>\n",
       "      <td>34.0</td>\n",
       "      <td>fe814f9d1b8a657f20a30666c230cba0ad41a3172d5a6d...</td>\n",
       "      <td>vermont fancy slacks (1)</td>\n",
       "      <td>Trousers</td>\n",
       "      <td>Garment Lower body</td>\n",
       "      <td>Check</td>\n",
       "      <td>Light Pink</td>\n",
       "      <td>Dusty Light</td>\n",
       "      <td>Pink</td>\n",
       "      <td>Trouser</td>\n",
       "      <td>Ladieswear</td>\n",
       "      <td>Ladieswear</td>\n",
       "      <td>Womens Tailoring</td>\n",
       "      <td>Trousers</td>\n",
       "      <td>Ankle-length trousers in woven fabric with cre...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>ACTIVE</td>\n",
       "      <td>Regularly</td>\n",
       "      <td>57.0</td>\n",
       "      <td>c6f0cb557151fb401df27f8626791514784426f0819c2d...</td>\n",
       "      <td>TANJA SKIRT</td>\n",
       "      <td>Skirt</td>\n",
       "      <td>Garment Lower body</td>\n",
       "      <td>All over pattern</td>\n",
       "      <td>Black</td>\n",
       "      <td>Dark</td>\n",
       "      <td>Black</td>\n",
       "      <td>Skirts</td>\n",
       "      <td>Divided</td>\n",
       "      <td>Divided</td>\n",
       "      <td>Divided Collection</td>\n",
       "      <td>Skirts</td>\n",
       "      <td>Long skirt in an airy weave with an elasticate...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>ACTIVE</td>\n",
       "      <td>Regularly</td>\n",
       "      <td>38.0</td>\n",
       "      <td>ff4d97d79ca2e789e8409411f8776eac9efe60cbab52f8...</td>\n",
       "      <td>Jeggings H.W</td>\n",
       "      <td>Trousers</td>\n",
       "      <td>Garment Lower body</td>\n",
       "      <td>Denim</td>\n",
       "      <td>Blue</td>\n",
       "      <td>Medium Dusty</td>\n",
       "      <td>Blue</td>\n",
       "      <td>Denim Trousers</td>\n",
       "      <td>Divided</td>\n",
       "      <td>Divided</td>\n",
       "      <td>Ladies Denim</td>\n",
       "      <td>Trousers Denim</td>\n",
       "      <td>Jeggings in washed, superstretch denim with a ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     FN  Active club_member_status fashion_news_frequency   age  \\\n",
       "0   NaN     NaN             ACTIVE                   None  31.0   \n",
       "1   NaN     NaN             ACTIVE                   None  48.0   \n",
       "2   NaN     NaN             ACTIVE                   None  33.0   \n",
       "3   1.0     1.0             ACTIVE              Regularly  31.0   \n",
       "4   1.0     1.0             ACTIVE              Regularly  29.0   \n",
       "5   1.0     1.0             ACTIVE              Regularly  27.0   \n",
       "6   1.0     1.0             ACTIVE              Regularly  50.0   \n",
       "7   1.0     1.0             ACTIVE              Regularly  21.0   \n",
       "8   NaN     NaN             ACTIVE                   None  44.0   \n",
       "9   NaN     NaN         PRE-CREATE                   None  25.0   \n",
       "10  1.0     1.0             ACTIVE              Regularly  34.0   \n",
       "11  1.0     1.0             ACTIVE              Regularly  57.0   \n",
       "12  1.0     1.0             ACTIVE              Regularly  38.0   \n",
       "\n",
       "                                          postal_code  \\\n",
       "0   71b88711bd37db08ac1549d73432852f664cb48be8d893...   \n",
       "1   4385d55783e67067b9768f0877107d3e6cd64f3bee08ce...   \n",
       "2   bf98f222ef9eb34b3bba2745452d5f6d2f395edc79a4f1...   \n",
       "3   5d3e0bac03cdc876b5a1d84fd7c2b2e7cefa40ddbe62be...   \n",
       "4   efd9030a7d5b5f1a6d03a1a24b1fab9931492256ce29e5...   \n",
       "5   76c7d8747a83d1c09d66e311b142d77c0fa1d8fb646c5a...   \n",
       "6   4e63dc705eb70e92b59132da6ff80f9841982d030f5178...   \n",
       "7   00b7efd47eeb50702752f1b9ffd8ebd953a54124aead10...   \n",
       "8   91bbfabb4917109c8a4d300fa95e514b7bbc251cea44e3...   \n",
       "9   570e2e8d4b0f09c94a88e52fb936234bf57da9943e142a...   \n",
       "10  fe814f9d1b8a657f20a30666c230cba0ad41a3172d5a6d...   \n",
       "11  c6f0cb557151fb401df27f8626791514784426f0819c2d...   \n",
       "12  ff4d97d79ca2e789e8409411f8776eac9efe60cbab52f8...   \n",
       "\n",
       "                      prod_name  product_type_name  product_group_name  \\\n",
       "0                         Emily             Blouse  Garment Upper body   \n",
       "1                 Rebecka Dress              Dress   Garment Full body   \n",
       "2                       Twister              Dress   Garment Full body   \n",
       "3   Simple as That Triangle Top         Bikini top            Swimwear   \n",
       "4             Charlene cardigan           Cardigan  Garment Upper body   \n",
       "5   POW Meet the parents dress.              Dress   Garment Full body   \n",
       "6          Cava Shirt Dress new              Dress   Garment Full body   \n",
       "7             Timeless Push Bra         Bikini top            Swimwear   \n",
       "8       Chia Seamless HW Tights    Leggings/Tights  Garment Lower body   \n",
       "9               Headphones EARS  Other accessories         Accessories   \n",
       "10     vermont fancy slacks (1)           Trousers  Garment Lower body   \n",
       "11                  TANJA SKIRT              Skirt  Garment Lower body   \n",
       "12                 Jeggings H.W           Trousers  Garment Lower body   \n",
       "\n",
       "   graphical_appearance_name colour_group_name perceived_colour_value_name  \\\n",
       "0                      Solid        Dark Green                      Medium   \n",
       "1           All over pattern             White                       Light   \n",
       "2                    Melange              Grey                Medium Dusty   \n",
       "3            Other structure        Dark Green                Medium Dusty   \n",
       "4                    Melange              Grey                Medium Dusty   \n",
       "5                      Solid         Dark Pink                Medium Dusty   \n",
       "6           All over pattern             Black                        Dark   \n",
       "7            Other structure             Black                        Dark   \n",
       "8                      Solid            Orange                      Bright   \n",
       "9                      Solid   Light Turquoise                       Light   \n",
       "10                     Check        Light Pink                 Dusty Light   \n",
       "11          All over pattern             Black                        Dark   \n",
       "12                     Denim              Blue                Medium Dusty   \n",
       "\n",
       "   perceived_colour_master_name       department_name  \\\n",
       "0                         Green                Blouse   \n",
       "1                         White                Jersey   \n",
       "2                          Grey          Jersey Basic   \n",
       "3                         Green              Swimwear   \n",
       "4                          Grey              Knitwear   \n",
       "5                          Pink                Jersey   \n",
       "6                         Black               Dresses   \n",
       "7                         Black              Swimwear   \n",
       "8                        Orange  Ladies Sport Bottoms   \n",
       "9                     Turquoise  Girls Small Acc/Bags   \n",
       "10                         Pink               Trouser   \n",
       "11                        Black                Skirts   \n",
       "12                         Blue        Denim Trousers   \n",
       "\n",
       "                        index_name index_group_name  \\\n",
       "0                       Ladieswear       Ladieswear   \n",
       "1                       Ladieswear       Ladieswear   \n",
       "2                       Ladieswear       Ladieswear   \n",
       "3                 Lingeries/Tights       Ladieswear   \n",
       "4                       Ladieswear       Ladieswear   \n",
       "5                       Ladieswear       Ladieswear   \n",
       "6                          Divided          Divided   \n",
       "7                 Lingeries/Tights       Ladieswear   \n",
       "8                            Sport            Sport   \n",
       "9   Children Accessories, Swimwear    Baby/Children   \n",
       "10                      Ladieswear       Ladieswear   \n",
       "11                         Divided          Divided   \n",
       "12                         Divided          Divided   \n",
       "\n",
       "                      section_name garment_group_name  \\\n",
       "0       Womens Everyday Collection            Blouses   \n",
       "1                             Mama       Jersey Fancy   \n",
       "2           Womens Everyday Basics       Jersey Basic   \n",
       "3       Womens Swimwear, beachwear           Swimwear   \n",
       "4                     Womens Trend           Knitwear   \n",
       "5                             H&M+       Jersey Fancy   \n",
       "6               Divided Collection     Dresses Ladies   \n",
       "7       Womens Swimwear, beachwear           Swimwear   \n",
       "8                 Ladies H&M Sport       Jersey Fancy   \n",
       "9   Kids Accessories, Swimwear & D        Accessories   \n",
       "10                Womens Tailoring           Trousers   \n",
       "11              Divided Collection             Skirts   \n",
       "12                    Ladies Denim     Trousers Denim   \n",
       "\n",
       "                                          detail_desc  label  \n",
       "0   Short top in an airy cotton weave. Square neck...      0  \n",
       "1   Short, fitted dress in soft, organic cotton je...      0  \n",
       "2   Calf-length jersey dress with draped sides, sh...      0  \n",
       "3   Lined, non-wired, triangle bikini top with a w...      0  \n",
       "4   Cardigan in chunky-knit, soft wool with button...      0  \n",
       "5   Calf-length lace dress with adjustable spaghet...      0  \n",
       "6   Short dress in a softly draping weave with a c...      0  \n",
       "7   Fully lined bikini top with a textured-stripe ...      0  \n",
       "8   Sports tights in ribbed, fast-drying functiona...      0  \n",
       "9   Adjustable, glittery, on-ear headphones with p...      1  \n",
       "10  Ankle-length trousers in woven fabric with cre...      0  \n",
       "11  Long skirt in an airy weave with an elasticate...      0  \n",
       "12  Jeggings in washed, superstretch denim with a ...      0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dataclasses import dataclass, asdict\n",
    "\n",
    "\n",
    "def main():\n",
    "    @dataclass\n",
    "    class Hyperparameters:\n",
    "        lr_rate: float = 1e-3\n",
    "        weight_decay: str = \"l2_reg\"\n",
    "        # Add more here...\n",
    "\n",
    "    # Load data\n",
    "    df_c, df_a, df_t = load_min_data(\n",
    "        [\n",
    "            f\"dataset_sample/{n}_min.csv\"\n",
    "            for n in (\"customer\", \"articles\", \"transactions\")\n",
    "        ]\n",
    "    )\n",
    "    df_c = clean_customer_data(df_c)\n",
    "\n",
    "    # Transform to training and testing set\n",
    "    dataset_params = {\n",
    "        \"total_cases\": 20,\n",
    "        \"portion_negatives\": 0.9,\n",
    "        \"df_transactions\": df_t,\n",
    "        \"df_articles\": df_a,\n",
    "        \"df_customers\": df_c,\n",
    "        \"train_portion\": 0.7,\n",
    "    }\n",
    "    data_train = HM_train(**dataset_params)\n",
    "    data_test = HM_val(**dataset_params)\n",
    "\n",
    "    model = HM_model(num_customer=20, num_transactions=20, embedding_size=5)\n",
    "    return data_train.train\n",
    "\n",
    "    # Train, eval, save results and weights...\n",
    "\n",
    "\n",
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('Proj': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "402b62e985bc5250c3cc67917d34a79ef392b62d1143c3e95347f6ab24b3a3fe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
